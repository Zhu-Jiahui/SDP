<!DOCTYPE html>
<html>
  <head>
    <title>Hello JITSI</title>
    <link href="styles/main.css" rel="stylesheet" type="text/css" />
        <script defer src="JS/sentimentAPI.js"></script>
        <script defer src="JS/sentiment.js"></script>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
        <script src="https://meet.jit.si/external_api.js"></script>
        
        <script>
        $(document).ready(function(){
          var domain = "meet.jit.si";
          var options = {
            roomName: "My Jitsi Meet Room",
            width: 500,
            height: 500,
            parentNode: document.querySelector('#meet')
          }
        var api = new JitsiMeetExternalAPI(domain, options);
        });
        </script>

        <script src="https://cdn.jsdelivr.net/npm/@widgetbot/crate@3" async defer>
    
        const button = new Crate({
        server: '681458022811566139',
        channel: '681458023280934960',
        shard: 'https://disweb.dashflo.net'
        })

        button.notify('Transcription is Started')

      

        var SpeechRecognition = SpeechRecognition || webkitSpeechRecognition;
        var SpeechGrammarList = SpeechGrammarList || webkitSpeechGrammarList;

        var grammar = '#JSGF V1.0;'; 

          const recognition = new SpeechRecognition();
          var speechRecognitionList = new SpeechGrammarList();
          speechRecognitionList.addFromString(grammar, 1);
          recognition.grammars = speechRecognitionList;
          recognition.lang = 'en-US';
          recognition.interimResults = true;

          let p = document.createElement('p');
          let words = document.createElement('words')
          var br = document.createElement('br');
          words.appendChild(br);
          words.appendChild(p);

          recognition.addEventListener('result', e=> {
            const transcript = Array.from(e.results)
              .map(result => result[0])
              .map(result => result.transcript)
              .join('')

              p.textContent = transcript;
              
              if(e.results[0].isFinal) {
                  console.log(p.textContent)
                  console.log(words.textContent)
                  button.notify(p.textContent)
                  button.emit('sendMessage', p.textContent)
                  p = document.createElement('p');
                  words.appendChild(br);
                  words.appendChild(p)
              }
          });
          recognition.addEventListener('end', recognition.start);

          recognition.start();

          </script>

  </head>
  <body>
    <header>
      <h1>Speech Recognition</h1>
      <nav>
        <ul>
          <li><a href="index.html">Home</a> </li>
          <li><a href="jitsi.html">Jitsi Meet</a></li>
          <li><a href="SpeechRecognition.html">Speech Recognition</a></li>
          <li><a href="test.html">test</a></li>
          <li><a href="sentiment.html">sentiment</a></li>
        </ul>
      </nav>
    </header>
    <video id = "video" width="0" height="0" autoplay muted></video>
    <div class="SentimentOutput" coifraintenteditable></div>
    <button>Sentiment Analysis</button>
    <widgetbot
      server="681458022811566139"
      channel="681458023280934960"
      width="500"
      height="600"
      shard="https://disweb.dashflo.net"
      class="embed"
    ></widgetbot>
    <script src="https://cdn.jsdelivr.net/npm/@widgetbot/html-embed"></script>
    
    <div id = "meet"></div>

</body>
</html>